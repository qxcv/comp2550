\documentclass[a4paper]{article}
\usepackage{%
    hyperref,xcolor,todonotes,tabularx,multirow,multicol,titling,grffile,
    amsmath,amssymb
}
\hypersetup{%
    % See
    % http://tex.stackexchange.com/questions/823/remove-ugly-borders-around-clickable-cross-references-and-hyperlinks
    colorlinks,
    linkcolor={red!50!black},
    citecolor={blue!50!black},
    urlcolor={blue!80!black}
}
\usepackage[round]{natbib}
% \usepackage[margin=1in]{geometry}

% Remember: should talk about the defects of the algorithm and how these could
% be fixed (e.g. with additional sensor data), as that was something Jose seemed
% quite intent on.

\newcommand{\mat}{\mathbf}
\renewcommand{\b}{\mathbf}

\begin{document}
    \title{Robust Map-Augmented Localisation Using Particle Filters\\
    {\Large COMP2550 Project Report}}
    \author{Sam Toyer\\\texttt{u5568237@anu.edu.au}}
    \date{\today}

    \maketitle

    % TODO: Rewrite this once I figure out what the hell my report is actually
    % about.
    \abstract{%
        In this paper, we propose a particle filtering method which fuses GPS
        fixes, odometry data, and the information in a digital street map to
        localise a road vehicle with superior accuracy to methods based on GPS
        and odometry alone. We demonstrate that our algorithm is robust to GPS
        dropouts, and give a variant of the algorithm which dispenses with the
        requirement for odometry.
    }

    \section{Introduction}

    % TODO: Might want to use localisation of visually impaired users as another
    % example (which I did in my proposal).

    Localisation is a critical task for intelligent transport systems, and
    features in systems ranging from personal navigation devices
    \citep{white2000some} to self-driving cars \citep{levinson2011towards}.
    Accurate localisation data can also be used to augment vehicle-based systems
    not directly related to navigation. For example, this work was motivated in
    part by the visual road detection algorithm presented by
    \citet{alvarez2014combining}, which projects road segments stored in a map
    database into the field of view of a camera in order determine which pixels
    produced by the camera are most likely to correspond to a road. Precise
    information about the location of the vehicle is clearly of the utmost
    importance in such systems.

    This task is complicated by the noise present in sensor readings. Despite
    its usefulness, GPS is a major offender in this regard: GPS accuracy can
    range from around 2m in an open area to up to 15m in heavily built-up areas
    \citep{modsching2006field}. Dead reckoning also suffers from significant
    errors, although unlike GPS error these tend to gradually increase over
    time. For instance, \citet{vlcek1993gps} report that low cost dead reckoning
    systems---typically based on odometry and gyroscope data---yield errors of
    between 2\% and 5\% of the distance travelled.

%     TODO: Is it okay to do this? It's not plagiarism, but it may violate
%     copyright. Should ask Steve or someone else who's likely to know. Maybe ANU
%     has a specific policy here. If not, I'll just leave the image out, since
%     it's not critical to the report.
%     \begin{figure}
%         \centering
%         \includegraphics[width=0.45\textwidth]{images/drawil-et-al.png}
%         \caption{Figure from \citet{drawil2013gps} demonstrating the GPS fixes
%         produced by a receiver in a vehicle as the vehicle drove through a built
%         up area. Grey lines indicate roads, whilst coloured dots indicate GPS
%         fixes, coloured according to the output of an automated precision
%         classifier.}
%         \label{fig:drawil-et-al}
%     \end{figure}

    Fortunately, road vehicles in motion are almost always situated on public
    roads, so it is possible to improve the accuracy of a localisation system by
    taking into account the information about the public road network which is
    present in a digital street map. With the advent of the OpenStreetMap
    project\footnotemark---which provides, free of charge, detailed road network
    maps covering most of the globe---use of map information in this way is
    quickly becoming a cheap and convenient method of augmenting the accuracy of
    existing localisation systems.

    \footnotetext{\url{http://www.openstreetmap.org/}}

    The most common method of incorporating this information is through ``map
    matching'', where localisation is performed under the simplifying assumption
    that the true location will \emph{always} coincide with a roadway, footpath
    or other mapped feature. In this paper, we will not make such a highly
    restrictive assumption. Instead, we will merely assume that the vehicle is
    \emph{most likely} near a roadway, and attempt to use this assumption to
    improve localisation accuracy as greatly as we can without losing the
    ability to localise vehicles which stray from the road network.

    \section{Related work}

    The approaches which presently dominate the map-assisted localisation
    literature are map matching methods which use sets of hand-crafted rules to
    determine which road segment in a digital map a vehicle is most likely to be
    travelling on, then attempt to localise the vehicle within that road
    segment. Typically, these approaches work by first assigning a ``score'' to
    each road segment in a digital street map based on the segment's distance
    from the vehicle's estimated position, the segment's heading, and so on, and
    then localise to the point on the highest scoring segment which is nearest
    to the last GPS fix or Kalman filter state estimate
    \citep{quddus2007current}.

    These heuristic methods can achieve very high accuracy. For example,
    \citet{quddus2006high} reported that the road segment scoring portion of
    their algorithm was able to correctly identify 99.2\% of the 4,605 road
    segments in one of their data sets. However, such high accuracy is not
    representative of all heuristic map matching
    algorithms---\citeauthor{quddus2006high} reported previous algorithms
    achieving 70\%-98\% segment identification accuracy where theirs achieved
    99.2\%---and usually requires large sets of hand-tuned rules. Moving from a
    rural to an urban environment, for instance, can sometimes reduce the
    usefulness of these rules, necessitating the production of yet more rules
    and heuristics for different environments \citep{velaga2012improving}.
    Further, heuristic map-matching algorithms are highly sensitive to initial
    conditions, as producing an incorrect first match will likely cause
    subsequent matches to be incorrect due to the fact that heuristic algorithms
    often assign low scores to road segments far away from previously matched
    segments \citep{syed2004fuzzy}.

    Probabilistic approaches to map aided localisation manage to avoid some of
    the pitfalls of heuristic approaches. Rather than producing a single ``best
    guess'' of the vehicle's state at each time step, probabilistic methods
    internally maintain a probability distribution over all possible vehicle
    states. This distribution may be updated sequentially, and used to produce
    the expectation of the vehicle's position at each time step. This approach
    makes it straightforward to incorporate almost any kind of data: for
    instance, \citet{brubaker2013lost} used a probabilistic approach based on
    Gaussian mixture models to localise a vehicle using only street map
    information and visual odometry---a feat which would be impossible with
    traditional heuristic map matching approaches. Probabilistic approaches also
    make it possible to relax the map matching assumption that the vehicle is
    always on a mapped feature, as it is straightforward to expand  the modelled
    distribution over possible vehicle states to cover both on-road and off-road
    areas.

    Particle filtering---also known as Monte Carlo localisation---is a popular
    probabilistic localisation method which has been employed for map aided
    localisation in a number of different ways. \citet{chausse2005vehicle}
    applied a particle filter to fuse odometry, GPS, vision and the information
    in a digital map, whilst \citet{selloum2009lane} and
    \citet{toledo2009fusing} used particle filtering with odometry, GPS and map
    information alone. In each instance, the authors reported excellent results,
    with all algorithms providing lane-level positioning accuracy in some cases.

    Unfortunately, the aforementioned approaches to probabilistic map-aided
    localisation both required sensors and information which are not always
    available. In all three cases, the algorithms required extremely precise
    maps offering a level of detail far beyond what could be expected of an
    ordinary digital street map used for navigation. Furthermore,
    \citeauthor{selloum2009lane} and \citeauthor{toledo2009fusing} both assumed
    the availability of a service like the European Geostationary Navigation
    Overlay Service (EGNOS) to correct GPS errors, whilst
    \citeauthor{chausse2005vehicle} required that the vehicle be fitted with a
    camera in order to achieve lane-level accuracy. These requirements are all
    difficult to satisfy for low-cost systems and systems which operate in
    remote regions, so one of our aims in this paper will be to dispense with
    these onerous requirements.

    \section{Our approach}\label{sec:algorithm}
    \subsection{Particle filtering}

    As mentioned previously, particle filtering is a probabilistic localisation
    method that is well suited to map-aided localisation. Internally, the
    particle filter represents a distribution over possible vehicle states with
    a fixed number of ``particles'', each of which represents a single sample
    from the following distribution \citep{fox1999monte}:

    \[
        p(s_t \mid o_t, a_{t-1}, o_{t-1}, a_{t-2}, \ldots, o_0)
    \]

    Where:

    \begin{description}
        \item[$s_t$] is the vehicle state at time $t$. This generally consists
        of a latitude, longitude and heading, but may contain more information
        in some cases.
        \item[$o_t$] represents the set of observations made by the vehicle's
        sensors at time $t$.
        \item[$a_t$] is the ``action'' taken by the vehicle at time $t$. Whilst
        these actions can correspond to throttle or steering wheel settings, it
        is also possible to consider actions to be more high level measurements
        like the distance travelled by the wheels of a vehicle in a single time
        step. Although these are technically sensory observations, we will soon
        see that it is convenient to treat them separately to the other
        observations $o_t$.
    \end{description}

    Over time, a particle filter updates its internal particle set using
    incoming observations and actions so that the particles remain distributed
    according to $p(s_t \mid o_t, a_{t-1}, \ldots, o_0)$. This process begins at
    time $t = 0$ by distributing the particles
    $\left\{s_0^{(n)}\right\}_{n=1}^N$ according to some chosen prior
    distribution over vehicle states. In our case, the positions of the initial
    particle set are samples from a Gaussian centered on the first available GPS
    fix, with particle yaws distributed uniformly.

    At each subsequent time step, the vehicle take an action $a_t$ to yield
    state $s_{t+1}$. After this, it may make a subsequent sensory observation
    $o_{t+1}$, which in our case will be a GPS fix. Using this new information,
    we may produce a new particle set $\left\{s_{t+1}^{(n)}\right\}_{n=1}^N$
    distributed according to $p(s_{t+1} \mid o_{t+1}, a_t, \ldots, o_0)$ from
    our previous particle set using the following process:

    \begin{enumerate}
        \item \textbf{Predict:} A new set of particles
        $\left\{{s_{t+1}^{(n)}}'\right\}_{n=1}^N$ is sampled from the transition
        distribution, $p(s_{t+1} \mid s_t, a_t)$, using the last observed action
        $a_t$ and the set of particles from the previous time step:
        \[
            {s_{t+1}^{(n)}}' \sim p(s_{t+1} \mid s_t^{(n)}, a_t)
        \]
        \item \textbf{Update:} Every ${s_{t+1}^{(n)}}'$ is then assigned a
        weight $w_{t+1}^{(n)}$ reflecting the likelihood of the most recent
        observation $o_{t+1}$ in $s_{t+1}^{(n)}$:
        \begin{equation}\label{eq:update}
            w_{t+1}^{(n)} = \tilde p(o_{t+1} \mid {s_{t+1}^{(n)}}')
        \end{equation}
        Where $\tilde p(o_{t+1} \mid {s_{t+1}^{(n)}}')$ is the likelihood of the
        observation $o_{t+1}$ being made in state $s_{t+1}^{(n)}$.
        \item \textbf{Resample:} Finally, a new set of particles
        $\left\{s_{t+1}^{(n)}\right\}_{n=1}^N$ is produced by drawing $N$
        particles, with replacement, from
        $\left\{{s_{t+1}^{(n)}}'\right\}_{n=1}^N$ using the weights
        $\left\{w_{t+1}^{(n)}\right\}_{n=1}^N$. In some cases, this resampling
        step is omitted, and the weight set is instead carried over to the next
        iteration, in which case the next set of particles will be calculates
        using
        \[
            w_{t+1}^{(n)} = w_t^{(n)} \tilde p(o_{t+1} \mid {s_{t+1}^{(n)}}')
        \]
        in preference to Equation~\ref{eq:update}. In some cases, the resampling
        step is only performed once the number of effective particles,
        $N_\mathrm{eff} = \left(\sum_{n=1}^N {w_t^{(n)}}^2\right)^{-1}$ falls
        below some threshold \citep{pf2002}.
    \end{enumerate}

    Finally, the expected vehicle position at time $t+1$ can be expressed as:

    \[
        \mathbb E[s_{t+1}] \approx \begin{cases}
            \frac{1}{N} \sum_{n=1}^N s_{t+1}^{(n)} & \text{if resampling was
            performed}\\
            \sum_{n=1}^N w_{t+1}^{(n)} s_{t+1}^{(n)} & \text{otherwise}
        \end{cases}
    \]

    In statistics, this process is known as Sequential Importance Resampling
    (SIR), and is explained at length by \citet{smith1992bayesian}. One
    important requirement of SIR is that states obey the Markov property; that
    is, the state $s_{t+1}$ is dependent only on the state $s_t$, the action
    $a_t$ and the observation $o_{t+1}$ \citep{dellaert1999monte}. In
    Section~\ref{sec:odomunavail}, we will investigate a case in which this
    property must be taken into consideration.

    \subsection{Basic particle filter configuration}

    In our implementation, we have chosen the state $s_t = (x_t, y_t,
    \theta_t)^T$ to contain an easting $x_t$, a northing $y_t$, and a yaw
    $\theta_t$. The observations $o_t = ({f_x}_t, {f_y}_t)^T$ consist of an
    easting ${f_x}_t$ and northing ${f_y}_t$ for the most recent GPS fix, whilst
    the actions $a_t = (v_t, \omega_t)^T$ contain a forward speed $v_t$ and a
    change in heading $\omega_t$, as might be reported by a speedometer and
    gyroscope, respectively.

    The transition distribution $p(s_{t+1} \mid s_t, a_t)$ chosen for our
    application updates particles utilising the vehicle's forward speed $v_t$
    and angular velocity $\omega_t$ at time $t$. Concretely, each particle
    particle $s_t^{(n)} = (x_t^{(n)}, y_t^{(n)}, \theta_t^{(n)})^T$ is updated
    using the following equations:

    % TODO: These aren't physically accurate. Should either cite someone who
    % does the same (wrong, but easy) thing or fix this problem by averaging
    % forward speeds at different time steps
    \begin{align*}
        \theta_{t+1} &= \theta_t + \omega_t' \Delta t\\
        x_{t+1} &= x_t + v_t' \cos(\theta_t) \Delta t\\
        y_{t+1} &= y_t + v_t' \sin(\theta_t) \Delta t
    \end{align*}

    Where $\omega_t' \sim \mathcal N(\omega_t, \sigma_\omega^2)$ and $v_t' \sim
    \mathcal N(v_t, \beta v_t^2)$ are random variables drawn from distributions
    representing uncertainty about the true speed and angular velocity of the
    vehicle \citep{thrun2001robust}. We found that the parameters
    $\sigma_\omega^2 = 0.15$ and $\beta = 0.36$ worked well for this purpose.

    When odometry is unavailable, it is not be possible to accurately derive the
    forward speed $v_t$ and angular velocity $\omega_t$ necessary to update
    particles using the aforementioned transition distribution. In
    Section~\ref{sec:odomunavail}, we will discuss the changes which must be
    made to the state representation and transition distribution in order to
    support localisation in this more challenging case.

    If a GPS fix at easting and northing $({f_x}_t, {f_y}_t)^T$ was observed
    between time steps $t$ and $t + 1$, we set the weight $w_{t+1}^{(n)}$
    associated with the particle $s_{t+1}^{(n)} = (x_t, y_t, \theta_t)^T$ to:

    \begin{equation}\label{eq:gpsweight}
        w_{t+1}^{(n)} = \exp\left(
            -\frac{1}{2} \left(
                \begin{bmatrix}x_t\\y_t\end{bmatrix}
                -
                \begin{bmatrix}{f_x}_t\\{f_y}_t\end{bmatrix}
            \right)^T \Sigma^{-1} \left(
                \begin{bmatrix}x_t\\y_t\end{bmatrix}
                -
                \begin{bmatrix}{f_x}_t\\{f_y}_t\end{bmatrix}
            \right)
        \right)
    \end{equation}

    This corresponds to an unnormalised Gaussian distribution with mean
    $({f_x}_t, {f_y}_t)^T$ and precision $\Sigma^{-1}$. We have found that a
    precision of the form $\sigma^{-2} I$, where $\sigma^{-2}$ is derived
    empirically, yields good results.

    In reality, GPS likelihood is not uniformly distributed, as GPS errors
    instead follow a complicated distribution governed by atmospheric
    interference, multipath fading, and other factors \citep{bajaj2002gps}.
    However, other authors have found similar Gaussian-based modelling
    strategies to be effective
    \citep{el2005road,selloum2009lane,toledo2009fusing}, so we have adopted one
    here.

    If GPS data is temporarily unavailable, we simply initialise weights
    uniformly, rather than applying Equation~\ref{eq:gpsweight}. Intuitively,
    this will cause particles to spread outwards according to the transition
    distribution until GPS fixes become available again to decrease the weight
    of particles far away from the vehicle's true position. This behaviour is
    examined as part of the qualitative comparison performed in
    Section~\ref{sec:results}.

    Every time a GPS fix becomes available, we also choose to scatter a small
    proportion (approximately 0.5\%) of particles in a normal distribution about
    the GPS fix. This ensures that the vehicle is able to re-localise itself
    correctly in the event that the particle filter's internal state estimate
    diverges too far from the vehicle's true position. Although there is no
    direct analogue to this strategy in the traditional SIR framework,
    \citet{fox1999monte} argue that it is theoretically sound in cases where the
    scattered particles are subsequently weighted correctly according to $p(o_t
    \mid s_t)$ and are sampled from a distribution which is nonzero over all
    locations where $p(s_t \mid o_t, a_{t-1}, \ldots, o_0)$ is nonzero.

    \subsection{Incorporating map data}
    \label{sec:mapdata}

    Whilst other authors have attempted to incorporate street map data into the
    particle filtering process by extending each particle's state to include an
    associated road segment \citep{selloum2009lane,toledo2009fusing}, we have
    found that the fastest way of incorporating map data is by way of a
    pseudo-likelihood during the particle filter's update step. Concretely, for
    each particle $s_t^{(n)}$, we calculate the distance $d_t^{(n)}$ to the road
    segment in the stored digital street map, then update the weight $w_t^{(n)}$
    of the stored particle using:

    % TODO: Update this when I'm finished. I'll probably choose a completely
    % different pseudolikelihood before I'm done, since this one seems
    % excessively restrictive (and leads to numerical issues).
    \begin{equation}\label{eq:mapweight}
        w_t^{(n)} \leftarrow \frac{w_t^{(n)}}{\left(1 + {d_t^{(n)}}^2\right)^{1.1}}
    \end{equation}

    Whilst this pseudo-likelihood is not reflective of the true likelihood
    $p(d_t^{(n)} \mid s_t^{(n)})$, we have nonetheless found that it does a
    reasonable job of forcing particles to remain near the road without
    preventing the particles from ``drifting'' away from the map when the
    vehicle's true position is far from a mapped feature. This ensures that the
    vehicle is still able to localise itself when it is travelling on unmapped
    roads.

    % TODO: Can probably motivate this a little more by referring to SIR. Also,
    % I really need to look into ignoring map updates when the map is a suitable
    % distance (100m? 500m?) from the nearest particle to the map.

    % Efficiently incorporating map data
    Despite being an efficient option amongst different methods of incorporating
    map data, computing the distance between each particle and its nearest road
    segment is still by far the most expensive step in the particle filtering
    process, so it is imperative that this computation be fast if real-time
    performance is desired. We have found that the k-d tree implementation
    provided by \citet{alliez20153d} yields good performance for this task,
    taking around 50ms to perform the calculations for 2000 particles on a map
    of 3220 segments using a 2.5GHz Intel Core i5 processor.

    \subsection{Unavailability of odometry}
    \label{sec:odomunavail}

    If odometry is unavailable, the transition model proposed previously will
    cease to work, so we must produce a new transition model and associated
    state representation which does not depend on odometry.

    One alternative model would be to adopt a stationary transition
    distribution, like a zero-mean Gaussian. Such a transition model would be
    efficient and simple, but would violate the assumption that vehicle states
    form a Markov chain, since clearly a vehicle which moves by a certain amount
    and in a certain direction at one time step is most likely to move by a
    similar amount and in a similar direction at the next. Concretely, violating
    this assumption means that particles either move too little or too much at
    each time step, depending on the vehicle's velocity.

    In theory, the Markov state transition assumption can only be restored by
    expanding the internal state representation to contain all relevant physical
    properties of the vehicle, including position, velocity, acceleration,
    heading, angular velocity, angular acceleration, and so on. This is, of
    course, impossible, so we have chosen to expand the state representation to
    contain only velocity and position. This does not truly satisfy the Markov
    state transition assumption, since the changes in a vehicle's velocity are
    heavily correlated over time, but we have nonetheless found that it produces
    acceptable results.

    Formally, operating without odometry requires that we replace our previous
    state vector $s = \left(x, y, \theta\right)^T$ with a new state vector $s =
    \left(x, y, v_x, v_y\right)^T$, where $v_x$ and $v_y$ are easting and
    northing velocities, respectively. Given state $s_t$, our transition model
    becomes:

    \[
        s_{t+1} = \begin{bmatrix}
        1 & 0 & \Delta t & 0\\
        0 & 1 & 0 & \Delta t\\
        0 & 0 & 1 & 0\\
        0 & 0 & 0 & 1
        \end{bmatrix} s_t + \begin{bmatrix}
        0\\
        0\\
        \epsilon_x\\
        \epsilon_y
        \end{bmatrix}
    \]

    % TODO: OMG I CAN DO AN AWESOME PLOT OF VELOCITY TRANSITION PROBABILITIES,
    % THEN FIT A COVARIANCE TO IT!
    Where $(\epsilon_x, \epsilon_y) \sim \mathcal N(\b 0, \sigma^2 \b I)$ and
    $\Delta_t$ is the time elapsed between the $s_t$ and $s_{t+1}$. We have
    found that $\sigma^2 = \Delta t$ works well, although in general it should
    be possible to fit an appropriate Gaussian from training data.

    \section{Results}\label{sec:results}

    In order to evaluate the performance the map-based localisation algorithm
    proposed in Section~\ref{sec:algorithm}, we utilised both quantitative and
    qualitative assessment. In the quantitative tests, we attempted to analyse
    the performance of the algorithm on partially artificial data for which it
    was straightforward to measure divergence from the ground truth. On the
    other hand, the qualitative tests attempted to examine algorithm performance
    using more realistic consumer-grade localisation data, which unfortunately
    did not include a ground truth for use in numerical comparisons.

    The code and data used to produce all figures and statistics in this report
    is available
    online.\footnote{\url{https://github.com/qxcv/comp2550/tree/master/project}}

    \subsection{Quantitative tests}

    The quantitative tests utilised the data set presented by
    \citet{brubaker2013lost}, which includes a number of GPS traces along with
    OpenStreetMap data for the regions immediately surrounding the traces. The
    supplied dataset included exceptionally accurate RTK-GPS positioning data,
    but no corresponding samples with a more representative noise model. As a
    result, we had to use a synthetic noise model to benchmark the algorithm,
    which included the following ``roughening'' steps:

    % TODO: Update this section with the parameters I *actually use* for the
    % final comparison.
    \begin{enumerate}
        \item Downsampling of GPS-like positioning information from 10Hz to 1Hz.
        \item Addition of isotropic Gaussian-distributed white noise with zero
        mean and variance $64\mathrm m^2$ to the positioning information.
        \item Rescaling of reported speed by a small but random factor of at
        most 1\% in order to emulate a subtly miscalibrated odometer.
        \item Addition of Gaussian noise with zero mean and standard deviation
        $4 \times 10^{-4}$ deg/$\mathrm s^2$ to the angular acceleration data.
    \end{enumerate}

    These parameters do not closely reflect the characteristics of real sensor
    noise. In particular, as mentioned previously, real GPS error tends to be
    highly time-correlated, but with an unpredictable distribution. Nonetheless,
    this ``roughening'' process does an excellent job of illustrating the
    difference in performance between plain particle filtering and map-aided
    particle filtering in the presence of non-ideal sensory input.

    \begin{figure}
        \centering
        \input{images/boxplot.pgf}
        \caption{Distribution of Horizontal Positioning Error (HPE) when using
        particle filtering with and without map information. Numbers at the top
        of each column indicate mean HPE. HPE was measured over time 10Hz on
        each of the 11 vehicle localisation traces provided by
        \citet{brubaker2013lost}.}
        \label{fig:boxplot}
    \end{figure}

    The results of this comparison are shown in Figure~\ref{fig:boxplot}.
    Clearly, map-aided particle filtering offers a significant advantage over
    plain particle filtering, with mean horizontal positioning error of the
    map-aided method usually around half that of the method with no map
    information.

    \begin{figure}
        \centering
        \includegraphics[width=0.4\textwidth]{images/map-spread.png}
        \includegraphics[width=0.4\textwidth]{images/no-map-spread.png}
        \caption{Images showing the particle spread induced by a map-aided
        particle filter (left) versus that induced by a non-map-aided particle
        filter (right). In each diagram, the road network is represented by the
        blue lines, the particle filter estimate is represented by a blue
        quadrilateral, the ground truth is represented by a green triangle, and
        the particles associated with the particle filter are drawn as red
        circles, with area directly proportional to weight. The red cross
        indicates the location of the most recent pseudo-GPS measurement.}
        \label{fig:latmove}
    \end{figure}

    Typically, the effect of the map data is to constrain the lateral movement
    of particles. Figure~\ref{fig:latmove} illustrates this phenomenon. Whilst
    the map prior does nothing to constrain the spread of the particles in the
    direction of the road, it does constrain the spread of the particles
    perpendicular to it. It is anticipated that this property would be
    especially useful in urban canyon environments, where GPS satellites on
    either side of a vehicle are typically blocked out by buildings. This has
    the effect of increasing positioning error perpendicular to the road without
    affecting positioning error in the direction of the road, so a weighting
    step which constrains particles to positions near the road should yield a
    significant increase in particle filter performance
    \citet{modsching2006field}.

    \begin{figure}
        \centering
        \includegraphics[width=0.6\textwidth]{images/wrong-road.png}
        \caption{In this scenario, the map weighting has made particle
        concentrate on two lanes on which the vehicle is not travelling, thus
        \emph{increasing} positioning error.}
        \label{fig:wrong-road}
    \end{figure}

    As Table~\ref{tab:times} attests, our implementation is able to run
    comfortably in real time on a desktop processor. Whilst use of map
    information incurs a significant performance penalty, it is still possible
    to produce predictions using thousands of particles at 10Hz. The current
    implementation, written in Python, is a proof-of-concept with few
    optimisations, so it is anticipated that even greater performance could be
    achieved by moving to a lower level language. Many steps of the sub-tasks
    performed by the algorithm---updating particle weights, predicting particle
    positions, etc.---are trivial to parallelise, so moving to a multi-threaded
    architecture could also boost performance.

    \begin{table}
        \centering
        \begin{tabular}{c|cccc}
            \input{times.tex}
        \end{tabular}
        \label{tab:times}
        \caption{
            Sum of processing times for the filter over all traces in the
            \citeauthor{brubaker2013lost} data set using different numbers of
            particles. In each case, the filter produced position estimates at
            10Hz for a total of 2320.1s (39 minutes) of traces. Statistics
            produced using a single core of a 2.8GHz AMD Phenom II processor.
        }
    \end{table}

    \subsection{Qualitative tests}

    The qualitative assessment used a GPS trace kindly provided by J. Alvarez
    (personal communication, May 12, 2015), which was produced from several
    kilometers of urban driving, including a brief GPS outage corresponding to a
    tunnel. The results of this test are presented in Figure~\ref{fig:qual}

    \begin{figure*}
    % See
    % https://tex.stackexchange.com/questions/122786/align-16-small-images-in-a-4-x-4-grid
    \centering
    \setlength{\tabcolsep}{0pt}
    % TODO: Good idea to timestamp these :-)
    \begin{tabular}{cccc}
    \multicolumn{4}{c}{With map information:}\\
    \includegraphics[width=0.25\textwidth]{spliced/with-map.avi-9.2.png}
    &
    \includegraphics[width=0.25\textwidth]{spliced/with-map.avi-12.4.png}
    &
    \includegraphics[width=0.25\textwidth]{spliced/with-map.avi-14.4.png}
    &
    \includegraphics[width=0.25\textwidth]{spliced/with-map.avi-16.8.png}
    \\
    \multicolumn{4}{c}{Without map information:}\\
    \includegraphics[width=0.25\textwidth]{spliced/without-map.avi-9.2.png}
    &
    \includegraphics[width=0.25\textwidth]{spliced/without-map.avi-12.4.png}
    &
    \includegraphics[width=0.25\textwidth]{spliced/without-map.avi-14.4.png}
    &
    \includegraphics[width=0.25\textwidth]{spliced/without-map.avi-16.8.png}\\
    {\small After initialisation} & {\small Entering tunnel} &
    \multicolumn{2}{c}{\small In tunnel; GPS unavailable}
    \end{tabular}
    \caption{Qualitative comparison of the map-aided particle filter (top) with
    an equivalent particle filter not making use of map information (bottom).
    Time flows from left to right. The most recent GPS fix in each frame is
    shown as a red cross, whilst the particle filter's state estimate is shown
    as a blue triangle and its particles are shown as red circles, with the area
    of each circle proportional to the corresponding particle's weight. The
    network of blue lines represent the centrelines of road lanes.}
    \label{fig:qual}
    \end{figure*}

    \subsection{Off-map localisation}

    % TODO: Do some benchmarks and write up this section. Also briefly mention
    % SLAM.

    \subsection{Shortcomings and possible improvements}

    Unfortunately, the algorithms tendency to draw particles in towards the road
    can, in some cases, decrease localisation performance. An example of this is
    given in Figure~\ref{fig:wrong-road}: the particle filter has localised
    itself on the left two lanes of the four lane road, but the vehicle is
    actually travelling in one of the right lanes. Fixing this defect is
    challenging, since GPS fixes and motion information alone does little to
    reliably disambiguate between lanes which could be separated by as little as
    three metres, especially when the mapped lane locations may be
    inaccurate---as is almost certainly the case with some OpenStreetMap data.
    Other authors have avoided this problem by using more accurate maps and
    augmented GPS \citep{selloum2009lane,toledo2009fusing}. Another common
    approach is to use first use a coarse localisation approach to determine
    approximate which road the vehicle is on, then employ computer vision
    algorithms to detect lane markings and/or curb locations
    \citep{chausse2005vehicle,montemerlo2008junior} in order to localise the
    vehicle \emph{within} the road. If sub-lane accuracy were required, then the
    current algorithm would have to be extended using one of these approaches.

    Figure~\ref{fig:wrong-road} also points to another issue with the algorithm:
    bimodal particle distributions. Particle filtering typically attempts to
    find the expectation of the posterior distribution over vehicle states, but
    this information is not useful in cases where the distribution is
    multimodal, like when the distribution is split across two lanes of a road.
    In this case, \emph{any} single state estimate is inappropriate,
    \citep{dellaert1999monte}, but if a ``sensible'' state estimate is always
    needed then it may help to apply clustering to the samples particles,
    followed by taking the expectation of those particles.

    At present, heading estimates are also difficult for the algorithm. Each
    particle includes a heading estimate for use in the prediction step of the
    particle filter, but no external heading observation is used to prevent the
    drift of these heading estimates. At high speeds, incorporating the heading
    estimated by the GPS unit into the particle filter update step may help,
    although this estimate does become highly volatile at low speeds
    \citep{ochieng2003map}. Further, weighting particles by the mismatch between
    their heading and that of the direction of traffic flow on the nearest road
    segments might prevent scenarios like that depicted in
    Figure~\ref{fig:wrong-road}, in which the majority of particles are
    travelling north, but are localised on lanes on which traffic can only go
    south! Unfortunately, incorporating this information would require
    additional manipulation of the digital map, which could prove too expensive
    for real-time application.

    Finally, the algorithm presented in this paper does not account for vehicle
    pitch, roll or altitude, nor for the elevation of the underlying road
    network. This information is seldom used in map matching algorithms,
    although there is at least one instance of vehicle elevation being used to
    improve GPS coverage by decreasing the number of satellites required for a
    GPS fix \citep{quddus2007current}. The algorithm presented in this paper
    could be extended to account for pitch, roll and altitude by modifying the
    state representation to include these quantities, as well as making use of
    attitude and altitude sensors during the particle filter update step.

    \section{Conclusion}

    % TODO

    \bibliography{citations}{}
    \bibliographystyle{abbrvnat}
\end{document}

